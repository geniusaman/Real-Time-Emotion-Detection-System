{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602bad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import Label, Canvas\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Set the mode based on your requirement (train/display)\n",
    "mode = \"display\"\n",
    "\n",
    "# Load pre-trained weights\n",
    "if mode == \"display\":\n",
    "    weights_path = r'D:\\mY_ZoNe\\My tasks\\Develop a real-time emotion detection system that operates on streaming video data and\\model.h5'\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "# Create Tkinter GUI window\n",
    "app = tk.Tk()\n",
    "app.title(\"Real-time Emotion Detection\")\n",
    "\n",
    "# Create labels to display emotion\n",
    "emotion_label = Label(app, text=\"Detected Emotion:\", font=(\"Helvetica\", 16))\n",
    "emotion_label.pack(pady=10)\n",
    "\n",
    "# Create canvas to display video feed\n",
    "canvas = Canvas(app, width=800, height=600)\n",
    "canvas.pack()\n",
    "\n",
    "# Function to update the canvas with the webcam feed\n",
    "def update_canvas(frame):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    "    photo = ImageTk.PhotoImage(image=Image.fromarray(frame))\n",
    "    canvas.create_image(0, 0, anchor=tk.NW, image=photo)\n",
    "    canvas.image = photo\n",
    "\n",
    "# Function to update the detected emotion label\n",
    "def update_emotion_label(emotion):\n",
    "    emotion_label.config(text=f\"Detected Emotion: {emotion}\")\n",
    "\n",
    "# Start the webcam feed and update the GUI\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Initialize the face cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "emotion_dict = {\n",
    "    0: 'Angry',\n",
    "    1: 'Disgust',\n",
    "    2: 'Fear',\n",
    "    3: 'Happy',\n",
    "    4: 'Sad',\n",
    "    5: 'Surprise',\n",
    "    6: 'Neutral'\n",
    "}\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Find faces and perform emotion detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "\n",
    "        cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
    "        prediction = model.predict(cropped_img)\n",
    "        maxindex = int(np.argmax(prediction))\n",
    "        detected_emotion = emotion_dict[maxindex]\n",
    "        cv2.putText(frame, detected_emotion, (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Update GUI\n",
    "        update_emotion_label(detected_emotion)\n",
    "\n",
    "    # Update canvas\n",
    "    update_canvas(frame)\n",
    "    app.update()\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# ... (rest of your code)\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec16f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9cc70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
